{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T14:32:15.170395248Z",
     "start_time": "2023-09-15T14:32:14.645462270Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import tools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'experiments.log' # Normal local tests\n",
    "#filename = 'experiments_E.log' # manual virtual wall tests\n",
    "filename = 'experiments_0.log' # Virtual wall tests\n",
    "\n",
    "interval = 19\n",
    "batch_count = 4\n",
    "experiment_batches = [f'experiments_{i * interval}.log' for i in range(batch_count)]\n",
    "print(experiment_batches)\n",
    "\n",
    "selected_batch = 1\n",
    "filename = experiment_batches[selected_batch-1]\n",
    "print(filename)\n",
    "\n",
    "filename = 'experiments_local.log' # Normal local tests\n",
    "filename = 'experiments_local2.log' # Normal local tests\n",
    "filename = 'experiments_local3.log' # Normal local tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T14:32:15.947966422Z",
     "start_time": "2023-09-15T14:32:15.170143155Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = tools.get_all_experiments(filename, align=True, interpolate=False, resample=False)\n",
    "experiments_resampled = tools.get_all_experiments(filename, align=True, interpolate=False, resample=True)\n",
    "# [experiment['directory'] for experiment in experiments]\n",
    "#len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_old = False\n",
    "if remove_old:\n",
    "    # Search for the lowest experiment id, and remember the dir that belongs to it\n",
    "    lowest_id = 1000000000000\n",
    "    lowest_dir = 0\n",
    "    for experiment in experiments:\n",
    "        if int(experiment['id']) < lowest_id:\n",
    "            lowest_id = int(experiment['id'])\n",
    "            lowest_dir = int(experiment['directory'])\n",
    "\n",
    "    # dir is an integer as a string, we want to filter out all the experiments that have a lower dir\n",
    "    experiments = [experiment for experiment in experiments if int(experiment['directory']) >= lowest_dir]\n",
    "\n",
    "    len(experiments)\n",
    "\n",
    "    # dir is an integer as a string, we want to filter out all the experiments that have a lower dir\n",
    "    experiments_resampled = [experiment_resampled for experiment_resampled in experiments_resampled if int(experiment_resampled['directory']) >= lowest_dir]\n",
    "\n",
    "len(experiments)\n",
    "\n",
    "#experiments[0]['dfs']['server_http']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = [ exp['info'] for exp in experiments]\n",
    "[jj['dir'] + ' ' + jj['fec'] + ' ' + jj['seg_dur'] for jj in ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments[0]['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_id_index(experiments):\n",
    "    if len(experiments) == 0:\n",
    "        return\n",
    "    # Search for the lowest id in the array: el['id]\n",
    "    min_id = int(experiments[0]['id'])\n",
    "    for experiment in experiments:\n",
    "        current_id = int(experiment['id'])\n",
    "        if current_id < min_id:\n",
    "            min_id = current_id\n",
    "    # Decrease the id of all the experiments by min_id\n",
    "    for experiment in experiments:\n",
    "        new_id = str(int(experiment['id']) - min_id)\n",
    "        experiment['id'] = new_id\n",
    "        experiment['info']['id'] = new_id\n",
    "\n",
    "reset_id_index(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-15T14:32:15.940215080Z"
    }
   },
   "outputs": [],
   "source": [
    "def take_window(df, column):\n",
    "    # Remove all the rows with 0 values, this removes the first rows\n",
    "    df = df.dropna().loc[(df!=0).any(axis=1)]\n",
    "    if (len(df) == 0):\n",
    "        return df\n",
    "    # Take the difference between rows, we want to find the last part where data is not increasing\n",
    "    df_diff = df.diff()\n",
    "    # Remove all non increasing rows\n",
    "    df_diff = df_diff.loc[(df_diff!=0).any(axis=1)]\n",
    "    if (len(df) == 0):\n",
    "        return df\n",
    "    # Get the last index of df_diff\n",
    "    last_index = df_diff.iloc[-1:].index[0]\n",
    "    # remove all rows from df after last_index\n",
    "    return df.loc[:last_index]\n",
    "\n",
    "\n",
    "def get_values(experiments, event, should_round=False):\n",
    "    dfs_found = {}\n",
    "    for experiment in experiments:\n",
    "        df = tools.get_metrics_by_events(\n",
    "            experiment['dfs'],\n",
    "            [event],\n",
    "            interpolate=False,\n",
    "        )\n",
    "        if df.size > 0:\n",
    "            df.columns = [experiment['id'] + ' ' + col for col in df.columns]\n",
    "            df_window = take_window(df, event)\n",
    "            if (len(df_window) == 0):\n",
    "                continue\n",
    "            # Get the first index of df_window\n",
    "            first_index = df_window.index[0]\n",
    "            # Get the last index of df_window\n",
    "            last_index = df_window.iloc[-1:].index[0]\n",
    "            # Get the first value\n",
    "            first_value = df_window.iloc[0].item()\n",
    "            # Get the last value\n",
    "            last_value = df_window.iloc[-1].item()\n",
    "            # Get the sum of all values\n",
    "            sum_value = df_window.sum().item()\n",
    "            # Get the max value\n",
    "            max_value = df_window.max().item()\n",
    "            # Get the difference between the first and last value\n",
    "            value_diff = (df_window.iloc[-1] - df_window.iloc[0]).item()\n",
    "            # Get the average value\n",
    "            avg_value = sum_value / len(df_window)\n",
    "\n",
    "            result = {\n",
    "                'id': experiment['id'],\n",
    "                'event': event,\n",
    "                'first': round(first_value, 3) if should_round else first_value,\n",
    "                'last': round(last_value, 3) if should_round else last_value,\n",
    "                'sum': round(sum_value, 3) if should_round else sum_value,\n",
    "                'max': round(max_value, 3) if should_round else max_value,\n",
    "                'diff': round(value_diff, 3) if should_round else value_diff,\n",
    "                'avg': round(avg_value, 3) if should_round else avg_value,\n",
    "                'start_index': first_index,\n",
    "                'end_index': last_index,\n",
    "            }\n",
    "            dfs_found[experiment['id']] = result\n",
    "\n",
    "    return dfs_found\n",
    "\n",
    "def convert_to_df(dictionaries, column_name, value_name='value'):\n",
    "    df = pd.DataFrame(dictionaries).T\n",
    "    if (len(df) == 0):\n",
    "        return df\n",
    "    df = df.pivot(index='id', columns='event', values=value_name).reset_index()\n",
    "    df = df.rename_axis(None, axis=1)\n",
    "    df = df.fillna(0)  # Replace NaN values with 0 if necessary\n",
    "    df['id'] = df['id'].astype(int)\n",
    "    df.set_index('id', inplace=True)  # Set 'id' as the index\n",
    "    # Get the event name from dict\n",
    "    event = list(dictionaries.values())[0]['event']\n",
    "\n",
    "    df = df.rename(columns={event: column_name})\n",
    "    return df.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two datetimes 1970 00:00:20 and 00:01:20\n",
    "\n",
    "def get_first_from_nested_list(nested_list):\n",
    "    if '[' in nested_list:\n",
    "        # Remove the '[' and ']'\n",
    "        nested_list = nested_list.replace('[', '').replace(']', '')\n",
    "        # Split by ','\n",
    "        nested_list = nested_list.split(',')[0]\n",
    "        # Remove the spaces\n",
    "        nested_list = nested_list.strip()\n",
    "        if '[' in nested_list:\n",
    "            # Remove the '[' and ']'\n",
    "            nested_list = nested_list.replace('[', '').replace(']', '')\n",
    "            # Split by ','\n",
    "            nested_list = nested_list.split(',')[0]\n",
    "            # Remove the spaces\n",
    "            nested_list = nested_list.strip()\n",
    "\n",
    "    # Remove ' and \" from the beginning and end\n",
    "    nested_list = nested_list.strip('\\'\"')\n",
    "    return nested_list\n",
    "\n",
    "def get_clients_sleep_time(clients_sleep_time):\n",
    "    clients_sleep_time = get_first_from_nested_list(clients_sleep_time)\n",
    "    return float(clients_sleep_time)\n",
    "\n",
    "\n",
    "clients_sleep_time = str(experiments[0]['info']['clients_sleep_time'])\n",
    "clients_sleep_time = get_clients_sleep_time(clients_sleep_time)\n",
    "segment_duration = int(experiments[0]['info']['seg_dur'])\n",
    "\n",
    "\n",
    "offset_time_delta = datetime.timedelta(seconds=clients_sleep_time - segment_duration)\n",
    "\n",
    "\n",
    "start_time = datetime.datetime(1970, 1, 1, 0, 0)\n",
    "end_time = datetime.datetime(1970, 1, 1, 0, 1, 36)\n",
    "\n",
    "avg_start_time = datetime.datetime(1970, 1, 1, 0, 0, 30)\n",
    "avg_end_time = datetime.datetime(1970, 1, 1, 0, 1, 15)\n",
    "\n",
    "print(offset_time_delta)\n",
    "print(start_time)\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_map = {\n",
    "    'live_latency': 'Live latency',\n",
    "}\n",
    "\n",
    "def get_legend_event(event):\n",
    "    if event in legend_map:\n",
    "        return legend_map[event]\n",
    "    \n",
    "    # Replace all underscores with spaces\n",
    "    event = event.replace('_', ' ')\n",
    "    # Capitalize the first letter of the event\n",
    "    event = event.capitalize()\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_title_map(video, seg_dur):\n",
    "    if video == 'avatarcmaf8' or video == 'avatarcmaf8_1':\n",
    "        return 'CMAF-CTE'\n",
    "    if video == 'avatarcmaf1' or video == 'avatarcmaf1_1':\n",
    "        return f'{seg_dur} sec segments'\n",
    "\n",
    "    return video\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_events(experiments,\n",
    "                events,\n",
    "                start_time=None,\n",
    "                end_time=None,\n",
    "                title='',\n",
    "                legend_title=None,\n",
    "                xlabel='Livestream time',\n",
    "                ylabel='',\n",
    "                figsize=(10, 3),\n",
    "                linewidth=2,\n",
    "                legend=True,\n",
    "                mc_only=False, # Only show results with multicast\n",
    "                no_mc_only=False, # Only show results without multicast\n",
    "                fec_only=False, # Only show results with FEC\n",
    "                no_fec_only=False, # Only show results without FEC\n",
    "                show_fec_legend=False,\n",
    "                legend_location='upper right',\n",
    "                legend_columns=1,\n",
    "                losses_to_plot=None,\n",
    "                offset_time_delta=offset_time_delta,\n",
    "                offset_time_on_playback=True,\n",
    "                offset_time_on_mc=True,\n",
    "                avg_between=[avg_start_time, avg_end_time],\n",
    "                show_video_title=True,\n",
    "                show_experiment_dir=False,\n",
    "                show_loss=False,\n",
    "                grid=False,\n",
    "                colors=None,\n",
    "                bottom_limit=None,\n",
    "                top_limit=None,\n",
    "                correct_latency=False,\n",
    "                extra_event_filter=None,\n",
    "                data_modifier=None):\n",
    "    combined_data = []\n",
    "    averages = {}\n",
    "    # Check if xlabel ends with ')', if not add ' (s)'\n",
    "    if xlabel[-1] != ')':\n",
    "        xlabel += ' (s)'\n",
    "\n",
    "    for experiment in experiments:\n",
    "        # Get the amount of loss for this experiment\n",
    "        loss = experiment['info']['loss']\n",
    "        if losses_to_plot is not None and float(loss) not in [float(l) for l in losses_to_plot]:\n",
    "            continue\n",
    "\n",
    "        multicast_enabled = experiment['info']['disable_multicast'] == '0' or experiment['info']['disable_multicast'] == 'False'\n",
    "        fec_enabled = experiment['info']['fec'] == '1'\n",
    "        video = get_first_from_nested_list(experiment['info']['videos'])\n",
    "        seg_dur = int(experiment['info']['seg_dur'])\n",
    "        video_title = video_title_map(video, seg_dur) + ' ' if show_video_title else ''\n",
    "        loss_text = (f'{loss} % loss' if multicast_enabled else 'No MC') if show_loss else ''\n",
    "        clients_sleep_time = get_clients_sleep_time(experiment['info']['clients_sleep_time'])\n",
    "        multicast_sleep_time = get_clients_sleep_time(experiment['info']['multicast_sender_sleep_time'])\n",
    "        wait_time = clients_sleep_time - multicast_sleep_time\n",
    "\n",
    "        experiment_title = video_title + loss_text + (' (FEC)' if fec_enabled else '')\n",
    "\n",
    "        if show_experiment_dir:\n",
    "            experiment_title += f' ({experiment[\"info\"][\"dir\"]})'\n",
    "\n",
    "        if mc_only and not multicast_enabled:\n",
    "            continue\n",
    "        if no_mc_only and multicast_enabled:\n",
    "            continue\n",
    "\n",
    "        if fec_only and not fec_enabled and multicast_enabled:\n",
    "            continue\n",
    "        if no_fec_only and fec_enabled and multicast_enabled:\n",
    "            continue\n",
    "\n",
    "        if offset_time_on_playback:\n",
    "            playback_data = tools.get_metrics_by_events(experiment['dfs'], ['playing'], interpolate=True)\n",
    "            # Get the first index where a value in the rows is not 0\n",
    "            # Replace NaN values with 0\n",
    "            playback_data = playback_data.fillna(0)\n",
    "            playback_data = playback_data.loc[(playback_data!=0).any(axis=1)]\n",
    "            # Get the first index of playback_data\n",
    "            if len(playback_data) > 0 :\n",
    "                offset_time_delta = playback_data.index[0]\n",
    "                if start_time is not None:\n",
    "                    # Substract the start_time from the offset_time_delta\n",
    "                    offset_time_delta = offset_time_delta - start_time\n",
    "\n",
    "\n",
    "        if offset_time_on_mc and multicast_enabled:\n",
    "            if offset_time_on_playback:\n",
    "                offset_time_delta = offset_time_delta - datetime.timedelta(seconds=wait_time)\n",
    "            else:\n",
    "                # Get the first index of the multicast data\n",
    "                multicast_data = tools.get_metrics_by_events(experiment['dfs'], ['is_multicasting'], interpolate=True)\n",
    "                # Get the first index of multicast_data\n",
    "                if len(multicast_data) > 0 :\n",
    "                    offset_time_delta = multicast_data.index[0]\n",
    "                    print(f'Offset time delta: {offset_time_delta}')\n",
    "                    if start_time is not None:\n",
    "                        # Substract the start_time from the offset_time_delta\n",
    "                        offset_time_delta = offset_time_delta - start_time\n",
    "                    if end_time is not None:\n",
    "                        # Add the segment duration to the offset_time_delta\n",
    "                        offset_time_delta = offset_time_delta + datetime.timedelta(seconds=segment_duration)\n",
    "            \n",
    "\n",
    "\n",
    "        experiment_data = tools.get_metrics_by_events(experiment['dfs'], events, interpolate=True)\n",
    "        # Check if the experiment has any data\n",
    "        if experiment_data.size > 0:\n",
    "            # The index is a datetime, we want to drop all the values before the offset_time\n",
    "            # experiment_data = experiment_data.loc[experiment_data.index >= offset_time_delta]\n",
    "            # Subtract the offset_time from the index\n",
    "            experiment_data.index = experiment_data.index - offset_time_delta\n",
    "\n",
    "            if extra_event_filter is not None:\n",
    "                # Only keep the columns where extra_event_filter(column) is true\n",
    "                experiment_data = experiment_data.loc[:, experiment_data.columns.map(extra_event_filter)]\n",
    "\n",
    "            if data_modifier is not None:\n",
    "                # check if it is a list\n",
    "                if isinstance(data_modifier, list):\n",
    "                    for modifier in data_modifier:\n",
    "                        experiment_data = modifier(experiment_data)\n",
    "                else:\n",
    "                    experiment_data = data_modifier(experiment_data)\n",
    "\n",
    "            if correct_latency:\n",
    "                # Correct the latency\n",
    "                experiment_data = experiment_data + wait_time\n",
    "\n",
    "            # Rename the columns\n",
    "            experiment_data.columns = [experiment_title for col in experiment_data.columns]\n",
    "\n",
    "            # Take a snapshot between avg_start_time and avg_end_time\n",
    "            avg_between = experiment_data.loc[avg_start_time:avg_end_time]\n",
    "            # Calculate the avg per column\n",
    "            avg_between = avg_between.mean()\n",
    "            # Print the avgs one by one\n",
    "            for index, value in avg_between.items():\n",
    "                print(f'Avg {index}: {value}')\n",
    "                averages[index] = value\n",
    "\n",
    "            combined_data.append(experiment_data)\n",
    "\n",
    "    # From averages, get all the keys with (FEC) in them\n",
    "    fec_keys = [key for key in averages.keys() if '(FEC)' in key]\n",
    "    # From averages, get all the keys without (FEC) in them and without 'No MC'\n",
    "    no_fec_keys = [key for key in averages.keys() if '(FEC)' not in key and 'No MC' not in key]\n",
    "    # Get the average of the averages\n",
    "    if len(fec_keys) > 0:\n",
    "        avg_fec = sum([averages[key] for key in fec_keys]) / len(fec_keys)\n",
    "        print(f'Avg FEC: {avg_fec}')\n",
    "    if len(no_fec_keys) > 0:\n",
    "        avg_no_fec = sum([averages[key] for key in no_fec_keys]) / len(no_fec_keys)\n",
    "        print(f'Avg No FEC: {avg_no_fec}')\n",
    "\n",
    "\n",
    "    tools.plot_data(combined_data, start_time=start_time, end_time=end_time, title=title, legend_title=legend_title, xlabel=xlabel, ylabel=ylabel, figsize=figsize, linewidth=linewidth, grid=grid, legend=legend, legend_location=legend_location, legend_columns=legend_columns, bottom_limit=bottom_limit, top_limit=top_limit, colors=colors, show_fec_legend=show_fec_legend) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxies_event_filter(event):\n",
    "    return 'proxy' in event\n",
    "\n",
    "def server_event_filter(event):\n",
    "    return 'server' in event\n",
    "\n",
    "def client_event_filter(event):\n",
    "    return 'lient' in event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data_by_1k(df):\n",
    "    return df / 1000\n",
    "\n",
    "def multiply_data_by_1k(df):\n",
    "    return df * 1000\n",
    "\n",
    "def remove_columns_with_only_zeros(df):\n",
    "    # Set the threshold for considering values as \"zero\"\n",
    "    threshold = 1.0e-10  # Adjust this threshold as needed\n",
    "\n",
    "    # Remove columns with values close to zero\n",
    "    return df.loc[:, (np.abs(df) > threshold).any(axis=0)]\n",
    "\n",
    "def fill_nan_with_zeros(df):\n",
    "    return df.fillna(0)\n",
    "\n",
    "def fill_nan_with_forward(df):\n",
    "    # Fill NaN values with the previous value\n",
    "    return df.ffill()\n",
    "\n",
    "def fill_nan_with_backward(df):\n",
    "    # Fill NaN values with the next value\n",
    "    return df.bfill()\n",
    "\n",
    "def fill_nan_with_linear(df):\n",
    "    # Fill NaN values with a linear interpolation\n",
    "    return df.interpolate(method='linear')\n",
    "\n",
    "def remove_nan(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def remove_ffill(df):\n",
    "    # Set all the values that are within threshold of the previous value to NaN\n",
    "    threshold = 1.0e-10  # Adjust this threshold as needed\n",
    "    return df.mask(df.sub(df.shift()).abs().lt(threshold))\n",
    "\n",
    "def remove_ffill_big(df):\n",
    "    df_copy = df.copy()\n",
    "    threshold = 0.002\n",
    "\n",
    "    # Round everything to 0.001\n",
    "    df_copy = df_copy.round(3)\n",
    "\n",
    "    for col in df_copy.columns:\n",
    "        diff_values = df_copy[col].diff()\n",
    "        indexes_to_replace = diff_values.abs() <= threshold\n",
    "\n",
    "        # Replace the values with NaN\n",
    "        df_copy.loc[indexes_to_replace, col] = np.nan\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "def set_nan_if_next_is_different(df):\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        diff_values = df_copy[col].diff()\n",
    "        indexes_to_replace = diff_values != 0\n",
    "\n",
    "        # Replace the values with NaN\n",
    "        df_copy.loc[indexes_to_replace, col] = np.nan\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "def set_nan_if_next_is_bigger(df):\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        diff_values = df_copy[col].diff()\n",
    "        indexes_to_replace = diff_values > 0\n",
    "\n",
    "        # Replace the values with NaN\n",
    "        df_copy.loc[indexes_to_replace, col] = np.nan\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "def round_down(df):\n",
    "    return df.round(0)\n",
    "\n",
    "def round_down_1(df):\n",
    "    return df.round(1)\n",
    "\n",
    "def round_down_2(df):\n",
    "    return df.round(2)\n",
    "\n",
    "def round_down_3(df):\n",
    "    return df.round(3)\n",
    "\n",
    "def round_up(df):\n",
    "    return df.apply(np.ceil)\n",
    "\n",
    "\n",
    "def resample_1ms(df):\n",
    "    return df.resample('0.001S').mean()\n",
    "\n",
    "def resample_1ms_ffill(df):\n",
    "    return fill_nan_with_forward(resample_1ms(df))\n",
    "\n",
    "def resample_1ms_bfill(df):\n",
    "    return fill_nan_with_backward(resample_1ms(df))\n",
    "\n",
    "def resample_1ms_linear(df):\n",
    "    return fill_nan_with_linear(resample_1ms(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['live_latency'], ylabel=\"Live latency (s)\", legend_location=\"upper right\", losses_to_plot=[0, 1 , 10, 20], start_time=start_time, end_time=end_time, data_modifier=[], correct_latency=True, show_experiment_dir=False, offset_time_on_mc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "def remove_trend(df):\n",
    "    global counter\n",
    "    counter += 1\n",
    "    if counter != 3:\n",
    "        return df\n",
    "    moving_avg = df['client_1_1 buffer_length'].rolling(100, min_periods=100).mean()\n",
    "    ema = df['client_1_1 buffer_length'].ewm(alpha=0.0005, adjust=False).mean()\n",
    "    df['client_1_1 buffer_length'] = df['client_1_1 buffer_length'] - ema + 0.8\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "plot_events(experiments_resampled, ['buffer_length'], ylabel=\"Buffer length (s)\", legend_location=\"upper right\", losses_to_plot=[0, 1 , 10, 20], start_time=start_time, end_time=end_time, data_modifier=[remove_nan, resample_1ms], no_fec_only=True, offset_time_on_mc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['check_md5_time'], ylabel=\"Time to check md5 (ms)\", legend_location=\"upper right\", losses_to_plot=None, start_time=start_time, end_time=end_time, extra_event_filter=proxies_event_filter, data_modifier=[remove_nan, resample_1ms_linear], xlabel=\"Multicast time\", offset_time_on_mc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['multicast_reception_time_before_deadline'], ylabel=\"Received before deadline (s)\", legend_location=\"upper right\", losses_to_plot=[0, 1, 10, 20], start_time=start_time, end_time=end_time, extra_event_filter=proxies_event_filter, data_modifier=[remove_nan, divide_data_by_1k], xlabel=\"Multicast time\", offset_time_on_mc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['multicast_reception_time_after_deadline'], ylabel=\"Time since PR (s)\", legend_location=\"upper right\", losses_to_plot=[0, 1, 10, 20, 40, 80], start_time=start_time, end_time=end_time, extra_event_filter=proxies_event_filter, data_modifier=[remove_nan, divide_data_by_1k], xlabel=\"Multicast time\", offset_time_on_mc=True, legend_columns=3, top_limit=1.16, bottom_limit=0, colors=['red', 'blue', 'green', 'orange', 'purple', 'brown'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['multicast_reception_time_after_deadline'], ylabel=\"Time since PR (s)\", legend_location=\"upper right\", losses_to_plot=[0, 1, 10, 20, 40, 80], start_time=start_time, end_time=end_time, extra_event_filter=proxies_event_filter, data_modifier=[remove_nan, divide_data_by_1k], xlabel=\"Multicast time\", offset_time_on_mc=True, show_video_title=False, show_loss=True, legend_columns=3, top_limit=1.16, bottom_limit=0, colors=['red', 'blue', 'green', 'orange', 'purple', 'brown'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['playback_rate'], ylabel=\"Playback rate\", legend_location=\"upper right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan], offset_time_on_mc=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['playing'], ylabel=\"Playback has started\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, round_up], xlabel=\"Multicast time\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['latency_average'], ylabel=\"Average request latency (ms)\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, round_down_2, multiply_data_by_1k] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['ratio_average'], ylabel=\"Average ratio\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['server_fetch_duration'], ylabel=\"Server latency (ms)\", legend_location=\"upper right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, divide_data_by_1k])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['symbols_received'], ylabel=\"Total symbols received\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, resample_1ms_ffill], xlabel=\"Multicast time\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['fdt_received'], ylabel=\"Total FDTs received\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, resample_1ms_ffill, round_down], xlabel=\"Multicast time\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['missing_symbols_gauge'], ylabel=\"Total symbols missing\", legend_location=\"upper right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan], xlabel=\"Multicast time\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['multicast_files_received'], ylabel=\"Files received over MC\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan,round_down], xlabel=\"Multicast time\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['multicast_files_sent'], ylabel=\"Files transmitted over MC\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, resample_1ms_ffill, set_nan_if_next_is_bigger, fill_nan_with_forward, round_down], xlabel=\"Multicast time\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['partial_requests'], ylabel=\"Recovery requess\", legend_location=\"upper left\", losses_to_plot=[0, 1, 10, 20], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, resample_1ms_ffill, set_nan_if_next_is_bigger, fill_nan_with_forward, round_down], xlabel=\"Multicast time\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['multicast_transmission_time'], ylabel=\"MC transmission time\", legend_location=\"upper right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan], xlabel=\"Multicast time\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['mtp'], ylabel=\"Average throughput (Mb/s)\", legend_location=\"upper left\", losses_to_plot=[0, 1, 10, 20], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, divide_data_by_1k, resample_1ms_ffill, set_nan_if_next_is_bigger, fill_nan_with_forward, round_down_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['files_fetched'], ylabel=\"Total files fetched\", legend_location=\"upper left\", losses_to_plot=[0, 1, 10, 20], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, round_down], xlabel=\"Multicast time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['alcs_ignored'], ylabel=\"Total number of ALCs ignored\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, round_down], xlabel=\"Multicast time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments, ['dropped_frames'], ylabel=\"Dropped frames\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, resample_1ms_ffill])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['partial_processing_duration'], ylabel=\"Time to prepare recovery (ms)\", legend_location=\"upper right\", losses_to_plot=[0, 1, 10, 20, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan,divide_data_by_1k, remove_columns_with_only_zeros], xlabel=\"Multicast time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['framerate'], ylabel=\"Frames per second\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan,remove_columns_with_only_zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_events(experiments_resampled, ['file_hash_mismatches'], ylabel=\"Total hash mismatches\", legend_location=\"lower right\", losses_to_plot=[0, 1, 10, 20, 40, 80], start_time=start_time, end_time=end_time, extra_event_filter=None, data_modifier=[remove_nan, round_down], xlabel=\"Multicast time\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
